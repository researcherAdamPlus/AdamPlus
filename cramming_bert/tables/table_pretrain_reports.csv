name	budget	dataset	backend	arch	loss	final_step	final_epoch	step_time	loss100k	loss200k	loss300k	total_time	batch_size	lr	warmup	steps	seed	dataset_hash	base_dir	impl_path	local_folder	Data_name	Data_sources	Data_hf_location	Data_streaming	Data_vocab_size	Data_seq_length	Arch_architectures	Arch_num_transformer_layers	Arch_hidden_size	Arch_intermed_size	Arch_hidden_dropout_prob	Arch_norm	Arch_norm_eps	Arch_norm_scheme	Arch_nonlin	Arch_tie_weights	Arch_decoder_bias	Arch_sparse_prediction	Arch_loss	Arch_objective_layout	Arch_embedding	Arch_attention	Arch_init	Arch_ffn_layer_frequency	Arch_skip_head_transform	Arch_use_bias	Arch_final_norm	Arch_num_labels	Arch_classification_head	Train_optim	Train_optim_mod	Train_name	Train_limited_decay_keys	Train_warmup_steps	Train_cooldown_steps	Train_steps	Train_scheduler	Train_batch_size	Train_batch_size_ramp	Train_gradient_clipping	Train_pretrain_in_train_mode	Train_objective	Train_reverse_dataset_order	Train_budget
amp_b8192_cb_o4_final	24	pile-readymade	torch-default	ScriptableCrammedBERT	2.070892095565796	102000	1	0.6984633031055039	2.076578140258789			19:50:44.026660	        8192	0.001	0	900000	32	2e382596fef989f92292d3d53214f2e7	/home/rostyslav/cramming/outputs	/home/rostyslav/cramming/outputs/data	amp_b8192_cb_o4_final/pretrain/2025-07-28/21-11-41	pile-readymade	{'hub': {'provider': 'hub'}}	JonasGeiping/the_pile_WordPiecex32768_2efdb9d060d1ae95faf952ec1a50f020	True	32768	128	['ScriptableCrammedBERT']	16	768	3072	0.1	LayerNorm	1e-12	pre	GELUglu	True	False	0.25	cross-entropy	MLM	{'vocab_size': None, 'pos_embedding': 'scaled-sinusoidal', 'dropout_prob': 0.1, 'pad_token_id': 0, 'max_seq_length': 128, 'embedding_dim': '${arch.hidden_size}', 'normalization': True, 'stable_low_precision': False}	{'type': 'self-attention', 'causal_attention': False, 'num_attention_heads': 12, 'dropout_prob': 0.1, 'skip_output_projection': False, 'qkv_bias': False, 'rotary_embedding': False, 'seq_op_in_fp32': False, 'sequence_op': 'torch-softmax'}	{'type': 'normal', 'std': 0.02}	1	True	False	True		{'pooler': 'avg', 'include_ff_layer': True, 'head_dim': 1024, 'nonlin': 'Tanh', 'classifier_dropout': '${arch.hidden_dropout_prob}'}	{'type': 'AdamW', 'lr': 0.001, 'betas': [0.9, 0.98], 'eps': 1e-12, 'weight_decay': 0.01, 'amsgrad': False, 'fused': None}	{'name': 'none'}	bert-o4	['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'norm']	0	0	900000	budget-triangle2	8192	0.6	0.5	False	{'name': 'masked-lm', 'mlm_probability': 0.25, 'use_80_20_rule': True, 'disable_mlm': False, 'token_drop': 0.0}	False	24
amp_b8192_cb_o4_final	24	pile-readymade	torch-default	ScriptableCrammedBERT	2.0004076957702637	115000	1	0.7499042526120725	2.051532030105591			1 day 0:00:04.589566	8192	0.001	0	900000	32	2e382596fef989f92292d3d53214f2e7	/home/rostyslav/cramming/outputs	/home/rostyslav/cramming/outputs/data	amp_b8192_cb_o4_final/pretrain/2025-07-28/21-11-13	pile-readymade	{'hub': {'provider': 'hub'}}	JonasGeiping/the_pile_WordPiecex32768_2efdb9d060d1ae95faf952ec1a50f020	True	32768	128	['ScriptableCrammedBERT']	16	768	3072	0.1	LayerNorm	1e-12	pre	GELUglu	True	False	0.25	cross-entropy	MLM	{'vocab_size': None, 'pos_embedding': 'scaled-sinusoidal', 'dropout_prob': 0.1, 'pad_token_id': 0, 'max_seq_length': 128, 'embedding_dim': '${arch.hidden_size}', 'normalization': True, 'stable_low_precision': False}	{'type': 'self-attention', 'causal_attention': False, 'num_attention_heads': 12, 'dropout_prob': 0.1, 'skip_output_projection': False, 'qkv_bias': False, 'rotary_embedding': False, 'seq_op_in_fp32': False, 'sequence_op': 'torch-softmax'}	{'type': 'normal', 'std': 0.02}	1	True	False	True		{'pooler': 'avg', 'include_ff_layer': True, 'head_dim': 1024, 'nonlin': 'Tanh', 'classifier_dropout': '${arch.hidden_dropout_prob}'}	{'type': 'AdamW+', 'lr': 0.001, 'beta1': 0.9, 'beta2': 0.98, 'eps': 1e-12, 'weight_decay': 0.01, 'amsgrad': False, 'is_mask': False, 'is_lamb': False, 'weight_decouple': True, 'db_noise': -140}	{'name': 'none'}	bert-o4	['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'norm']	0	0	900000	budget-triangle2	8192	0.6	0.5	False	{'name': 'masked-lm', 'mlm_probability': 0.25, 'use_80_20_rule': True, 'disable_mlm': False, 'token_drop': 0.0}	False	24
amp_b8192_cb_o4_final	24	pile-readymade	torch-default	ScriptableCrammedBERT	2.0131874084472656	120000	1	0.7192378806829453	2.0707876682281494			1 day 0:00:06.196770	8192	0.001	0	900000	32	2e382596fef989f92292d3d53214f2e7	/home/rostyslav/cramming/outputs	/home/rostyslav/cramming/outputs/data	amp_b8192_cb_o4_final/pretrain/2025-08-17/14-40-30	pile-readymade	{'hub': {'provider': 'hub'}}	JonasGeiping/the_pile_WordPiecex32768_2efdb9d060d1ae95faf952ec1a50f020	True	32768	128	['ScriptableCrammedBERT']	16	768	3072	0.1	LayerNorm	1e-12	pre	GELUglu	True	False	0.25	cross-entropy	MLM	{'vocab_size': None, 'pos_embedding': 'scaled-sinusoidal', 'dropout_prob': 0.1, 'pad_token_id': 0, 'max_seq_length': 128, 'embedding_dim': '${arch.hidden_size}', 'normalization': True, 'stable_low_precision': False}	{'type': 'self-attention', 'causal_attention': False, 'num_attention_heads': 12, 'dropout_prob': 0.1, 'skip_output_projection': False, 'qkv_bias': False, 'rotary_embedding': False, 'seq_op_in_fp32': False, 'sequence_op': 'torch-softmax'}	{'type': 'normal', 'std': 0.02}	1	True	False	True		{'pooler': 'avg', 'include_ff_layer': True, 'head_dim': 1024, 'nonlin': 'Tanh', 'classifier_dropout': '${arch.hidden_dropout_prob}'}	{'type': 'AdamW', 'lr': 0.001, 'betas': [0.9, 0.98], 'eps': 1e-12, 'weight_decay': 0.01, 'amsgrad': False, 'fused': None}	{'name': 'none'}	bert-o4	['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'norm']	0	0	900000	budget-triangle2	8192	0.6	0.5	False	{'name': 'masked-lm', 'mlm_probability': 0.25, 'use_80_20_rule': True, 'disable_mlm': False, 'token_drop': 0.0}	False	24
amp_b8192_cb_o4_final	24	pile-readymade	torch-default	ScriptableCrammedBERT	1.9765682220458984	122000	1	0.7055311311502925	2.074096441268921			1 day 0:00:05.592184	8192	0.001	0	900000	32	2e382596fef989f92292d3d53214f2e7	/home/rostyslav/cramming/outputs	/home/rostyslav/cramming/outputs/data	amp_b8192_cb_o4_final/pretrain/2025-08-17/14-58-29	pile-readymade	{'hub': {'provider': 'hub'}}	JonasGeiping/the_pile_WordPiecex32768_2efdb9d060d1ae95faf952ec1a50f020	True	32768	128	['ScriptableCrammedBERT']	16	768	3072	0.1	LayerNorm	1e-12	pre	GELUglu	True	False	0.25	cross-entropy	MLM	{'vocab_size': None, 'pos_embedding': 'scaled-sinusoidal', 'dropout_prob': 0.1, 'pad_token_id': 0, 'max_seq_length': 128, 'embedding_dim': '${arch.hidden_size}', 'normalization': True, 'stable_low_precision': False}	{'type': 'self-attention', 'causal_attention': False, 'num_attention_heads': 12, 'dropout_prob': 0.1, 'skip_output_projection': False, 'qkv_bias': False, 'rotary_embedding': False, 'seq_op_in_fp32': False, 'sequence_op': 'torch-softmax'}	{'type': 'normal', 'std': 0.02}	1	True	False	True		{'pooler': 'avg', 'include_ff_layer': True, 'head_dim': 1024, 'nonlin': 'Tanh', 'classifier_dropout': '${arch.hidden_dropout_prob}'}	{'type': 'AdamW+', 'lr': 0.001, 'beta1': 0.9, 'beta2': 0.98, 'eps': 1e-12, 'weight_decay': 0.01, 'amsgrad': False, 'is_mask': False, 'is_lamb': False, 'weight_decouple': True, 'db_noise': -140}	{'name': 'none'}	bert-o4	['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'norm']	0	0	900000	budget-triangle2	8192	0.6	0.5	False	{'name': 'masked-lm', 'mlm_probability': 0.25, 'use_80_20_rule': True, 'disable_mlm': False, 'token_drop': 0.0}	False	24
amp_b8192_cb_o4_final	24	pile-readymade	torch-default	ScriptableCrammedBERT	1.9428969621658325	111000	1	0.7080050704242946	2.0768327713012695			21:51:25.701717	        8192	0.001	0	900000	33	2e382596fef989f92292d3d53214f2e7	/home/rostyslav/cramming/outputs	/home/rostyslav/cramming/outputs/data	amp_b8192_cb_o4_final/pretrain/2025-08-18/15-01-56	pile-readymade	{'hub': {'provider': 'hub'}}	JonasGeiping/the_pile_WordPiecex32768_2efdb9d060d1ae95faf952ec1a50f020	True	32768	128	['ScriptableCrammedBERT']	16	768	3072	0.1	LayerNorm	1e-12	pre	GELUglu	True	False	0.25	cross-entropy	MLM	{'vocab_size': None, 'pos_embedding': 'scaled-sinusoidal', 'dropout_prob': 0.1, 'pad_token_id': 0, 'max_seq_length': 128, 'embedding_dim': '${arch.hidden_size}', 'normalization': True, 'stable_low_precision': False}	{'type': 'self-attention', 'causal_attention': False, 'num_attention_heads': 12, 'dropout_prob': 0.1, 'skip_output_projection': False, 'qkv_bias': False, 'rotary_embedding': False, 'seq_op_in_fp32': False, 'sequence_op': 'torch-softmax'}	{'type': 'normal', 'std': 0.02}	1	True	False	True		{'pooler': 'avg', 'include_ff_layer': True, 'head_dim': 1024, 'nonlin': 'Tanh', 'classifier_dropout': '${arch.hidden_dropout_prob}'}	{'type': 'AdamW+', 'lr': 0.001, 'beta1': 0.9, 'beta2': 0.98, 'eps': 1e-12, 'weight_decay': 0.01, 'amsgrad': False, 'is_mask': False, 'is_lamb': False, 'weight_decouple': True, 'db_noise': -140}	{'name': 'none'}	bert-o4	['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'norm']	0	0	900000	budget-triangle2	8192	0.6	0.5	False	{'name': 'masked-lm', 'mlm_probability': 0.25, 'use_80_20_rule': True, 'disable_mlm': False, 'token_drop': 0.0}	False	24
amp_b8192_cb_o4_final	24	pile-readymade	torch-default	ScriptableCrammedBERT	2.0298125743865967	119000	1	0.7227171897367268	2.0703532695770264			1 day 0:00:04.545677	8192	0.001	0	900000	33	2e382596fef989f92292d3d53214f2e7	/home/rostyslav/cramming/outputs	/home/rostyslav/cramming/outputs/data	amp_b8192_cb_o4_final/pretrain/2025-08-18/15-01-22	pile-readymade	{'hub': {'provider': 'hub'}}	JonasGeiping/the_pile_WordPiecex32768_2efdb9d060d1ae95faf952ec1a50f020	True	32768	128	['ScriptableCrammedBERT']	16	768	3072	0.1	LayerNorm	1e-12	pre	GELUglu	True	False	0.25	cross-entropy	MLM	{'vocab_size': None, 'pos_embedding': 'scaled-sinusoidal', 'dropout_prob': 0.1, 'pad_token_id': 0, 'max_seq_length': 128, 'embedding_dim': '${arch.hidden_size}', 'normalization': True, 'stable_low_precision': False}	{'type': 'self-attention', 'causal_attention': False, 'num_attention_heads': 12, 'dropout_prob': 0.1, 'skip_output_projection': False, 'qkv_bias': False, 'rotary_embedding': False, 'seq_op_in_fp32': False, 'sequence_op': 'torch-softmax'}	{'type': 'normal', 'std': 0.02}	1	True	False	True		{'pooler': 'avg', 'include_ff_layer': True, 'head_dim': 1024, 'nonlin': 'Tanh', 'classifier_dropout': '${arch.hidden_dropout_prob}'}	{'type': 'AdamW', 'lr': 0.001, 'betas': [0.9, 0.98], 'eps': 1e-12, 'weight_decay': 0.01, 'amsgrad': False, 'fused': None}	{'name': 'none'}	bert-o4	['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'norm']	0	0	900000	budget-triangle2	8192	0.6	0.5	False	{'name': 'masked-lm', 'mlm_probability': 0.25, 'use_80_20_rule': True, 'disable_mlm': False, 'token_drop': 0.0}	False	24
amp_b8192_cb_o4_final	24	pile-readymade	torch-default	ScriptableCrammedBERT	1.9427635669708252	123000	1	0.6988267761226592	2.086176872253418			1 day 0:00:04.128487	8192	0.001	0	900000	34	2e382596fef989f92292d3d53214f2e7	/home/rostyslav/cramming/outputs	/home/rostyslav/cramming/outputs/data	amp_b8192_cb_o4_final/pretrain/2025-08-19/16-45-16	pile-readymade	{'hub': {'provider': 'hub'}}	JonasGeiping/the_pile_WordPiecex32768_2efdb9d060d1ae95faf952ec1a50f020	True	32768	128	['ScriptableCrammedBERT']	16	768	3072	0.1	LayerNorm	1e-12	pre	GELUglu	True	False	0.25	cross-entropy	MLM	{'vocab_size': None, 'pos_embedding': 'scaled-sinusoidal', 'dropout_prob': 0.1, 'pad_token_id': 0, 'max_seq_length': 128, 'embedding_dim': '${arch.hidden_size}', 'normalization': True, 'stable_low_precision': False}	{'type': 'self-attention', 'causal_attention': False, 'num_attention_heads': 12, 'dropout_prob': 0.1, 'skip_output_projection': False, 'qkv_bias': False, 'rotary_embedding': False, 'seq_op_in_fp32': False, 'sequence_op': 'torch-softmax'}	{'type': 'normal', 'std': 0.02}	1	True	False	True		{'pooler': 'avg', 'include_ff_layer': True, 'head_dim': 1024, 'nonlin': 'Tanh', 'classifier_dropout': '${arch.hidden_dropout_prob}'}	{'type': 'AdamW', 'lr': 0.001, 'betas': [0.9, 0.98], 'eps': 1e-12, 'weight_decay': 0.01, 'amsgrad': False, 'fused': None}	{'name': 'none'}	bert-o4	['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'norm']	0	0	900000	budget-triangle2	8192	0.6	0.5	False	{'name': 'masked-lm', 'mlm_probability': 0.25, 'use_80_20_rule': True, 'disable_mlm': False, 'token_drop': 0.0}	False	24
amp_b8192_cb_o4_final	24	pile-readymade	torch-default	ScriptableCrammedBERT	1.9725075960159302	120000	1	0.7154775561153888	2.063091278076172			1 day 0:00:04.292389	8192	0.001	0	900000	35	2e382596fef989f92292d3d53214f2e7	/home/rostyslav/cramming/outputs	/home/rostyslav/cramming/outputs/data	amp_b8192_cb_o4_final/pretrain/2025-08-20/22-45-56	pile-readymade	{'hub': {'provider': 'hub'}}	JonasGeiping/the_pile_WordPiecex32768_2efdb9d060d1ae95faf952ec1a50f020	True	32768	128	['ScriptableCrammedBERT']	16	768	3072	0.1	LayerNorm	1e-12	pre	GELUglu	True	False	0.25	cross-entropy	MLM	{'vocab_size': None, 'pos_embedding': 'scaled-sinusoidal', 'dropout_prob': 0.1, 'pad_token_id': 0, 'max_seq_length': 128, 'embedding_dim': '${arch.hidden_size}', 'normalization': True, 'stable_low_precision': False}	{'type': 'self-attention', 'causal_attention': False, 'num_attention_heads': 12, 'dropout_prob': 0.1, 'skip_output_projection': False, 'qkv_bias': False, 'rotary_embedding': False, 'seq_op_in_fp32': False, 'sequence_op': 'torch-softmax'}	{'type': 'normal', 'std': 0.02}	1	True	False	True		{'pooler': 'avg', 'include_ff_layer': True, 'head_dim': 1024, 'nonlin': 'Tanh', 'classifier_dropout': '${arch.hidden_dropout_prob}'}	{'type': 'AdamW', 'lr': 0.001, 'betas': [0.9, 0.98], 'eps': 1e-12, 'weight_decay': 0.01, 'amsgrad': False, 'fused': None}	{'name': 'none'}	bert-o4	['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'norm']	0	0	900000	budget-triangle2	8192	0.6	0.5	False	{'name': 'masked-lm', 'mlm_probability': 0.25, 'use_80_20_rule': True, 'disable_mlm': False, 'token_drop': 0.0}	False	24
amp_b8192_cb_o4_final	24	pile-readymade	torch-default	ScriptableCrammedBERT	2.064676523208618	114000	1	0.7518616498415931	2.054640531539917			1 day 0:00:03.512480	8192	0.001	0	900000	35	2e382596fef989f92292d3d53214f2e7	/home/rostyslav/cramming/outputs	/home/rostyslav/cramming/outputs/data	amp_b8192_cb_o4_final/pretrain/2025-08-21/09-22-56	pile-readymade	{'hub': {'provider': 'hub'}}	JonasGeiping/the_pile_WordPiecex32768_2efdb9d060d1ae95faf952ec1a50f020	True	32768	128	['ScriptableCrammedBERT']	16	768	3072	0.1	LayerNorm	1e-12	pre	GELUglu	True	False	0.25	cross-entropy	MLM	{'vocab_size': None, 'pos_embedding': 'scaled-sinusoidal', 'dropout_prob': 0.1, 'pad_token_id': 0, 'max_seq_length': 128, 'embedding_dim': '${arch.hidden_size}', 'normalization': True, 'stable_low_precision': False}	{'type': 'self-attention', 'causal_attention': False, 'num_attention_heads': 12, 'dropout_prob': 0.1, 'skip_output_projection': False, 'qkv_bias': False, 'rotary_embedding': False, 'seq_op_in_fp32': False, 'sequence_op': 'torch-softmax'}	{'type': 'normal', 'std': 0.02}	1	True	False	True		{'pooler': 'avg', 'include_ff_layer': True, 'head_dim': 1024, 'nonlin': 'Tanh', 'classifier_dropout': '${arch.hidden_dropout_prob}'}	{'type': 'AdamW+', 'lr': 0.001, 'beta1': 0.9, 'beta2': 0.98, 'eps': 1e-12, 'weight_decay': 0.01, 'amsgrad': False, 'is_mask': False, 'is_lamb': False, 'weight_decouple': True, 'db_noise': -140}	{'name': 'none'}	bert-o4	['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'norm']	0	0	900000	budget-triangle2	8192	0.6	0.5	False	{'name': 'masked-lm', 'mlm_probability': 0.25, 'use_80_20_rule': True, 'disable_mlm': False, 'token_drop': 0.0}	False	24
amp_b8192_cb_o4_final	24	pile-readymade	torch-default	ScriptableCrammedBERT	1.9595203399658203	117000	1	0.7354877355567411	2.0662574768066406			1 day 0:00:03.918527	8192	0.001	0	900000	34	2e382596fef989f92292d3d53214f2e7	/home/rostyslav/cramming/outputs	/home/rostyslav/cramming/outputs/data	amp_b8192_cb_o4_final/pretrain/2025-08-22/11-02-07	pile-readymade	{'hub': {'provider': 'hub'}}	JonasGeiping/the_pile_WordPiecex32768_2efdb9d060d1ae95faf952ec1a50f020	True	32768	128	['ScriptableCrammedBERT']	16	768	3072	0.1	LayerNorm	1e-12	pre	GELUglu	True	False	0.25	cross-entropy	MLM	{'vocab_size': None, 'pos_embedding': 'scaled-sinusoidal', 'dropout_prob': 0.1, 'pad_token_id': 0, 'max_seq_length': 128, 'embedding_dim': '${arch.hidden_size}', 'normalization': True, 'stable_low_precision': False}	{'type': 'self-attention', 'causal_attention': False, 'num_attention_heads': 12, 'dropout_prob': 0.1, 'skip_output_projection': False, 'qkv_bias': False, 'rotary_embedding': False, 'seq_op_in_fp32': False, 'sequence_op': 'torch-softmax'}	{'type': 'normal', 'std': 0.02}	1	True	False	True		{'pooler': 'avg', 'include_ff_layer': True, 'head_dim': 1024, 'nonlin': 'Tanh', 'classifier_dropout': '${arch.hidden_dropout_prob}'}	{'type': 'AdamW+', 'lr': 0.001, 'beta1': 0.9, 'beta2': 0.98, 'eps': 1e-12, 'weight_decay': 0.01, 'amsgrad': False, 'is_mask': False, 'is_lamb': False, 'weight_decouple': True, 'db_noise': -140}	{'name': 'none'}	bert-o4	['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'norm']	0	0	900000	budget-triangle2	8192	0.6	0.5	False	{'name': 'masked-lm', 'mlm_probability': 0.25, 'use_80_20_rule': True, 'disable_mlm': False, 'token_drop': 0.0}	False	24
amp_b8192_cb_o4_final	24	pile-readymade	torch-default	ScriptableCrammedBERT	1.9362620115280151	121000	1	0.7129410038526393	2.055691719055176			1 day 0:00:04.148767	8192	0.001	0	900000	36	2e382596fef989f92292d3d53214f2e7	/home/rostyslav/cramming/outputs	/home/rostyslav/cramming/outputs/data	amp_b8192_cb_o4_final/pretrain/2025-08-22/11-05-26	pile-readymade	{'hub': {'provider': 'hub'}}	JonasGeiping/the_pile_WordPiecex32768_2efdb9d060d1ae95faf952ec1a50f020	True	32768	128	['ScriptableCrammedBERT']	16	768	3072	0.1	LayerNorm	1e-12	pre	GELUglu	True	False	0.25	cross-entropy	MLM	{'vocab_size': None, 'pos_embedding': 'scaled-sinusoidal', 'dropout_prob': 0.1, 'pad_token_id': 0, 'max_seq_length': 128, 'embedding_dim': '${arch.hidden_size}', 'normalization': True, 'stable_low_precision': False}	{'type': 'self-attention', 'causal_attention': False, 'num_attention_heads': 12, 'dropout_prob': 0.1, 'skip_output_projection': False, 'qkv_bias': False, 'rotary_embedding': False, 'seq_op_in_fp32': False, 'sequence_op': 'torch-softmax'}	{'type': 'normal', 'std': 0.02}	1	True	False	True		{'pooler': 'avg', 'include_ff_layer': True, 'head_dim': 1024, 'nonlin': 'Tanh', 'classifier_dropout': '${arch.hidden_dropout_prob}'}	{'type': 'AdamW', 'lr': 0.001, 'betas': [0.9, 0.98], 'eps': 1e-12, 'weight_decay': 0.01, 'amsgrad': False, 'fused': None}	{'name': 'none'}	bert-o4	['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'norm']	0	0	900000	budget-triangle2	8192	0.6	0.5	False	{'name': 'masked-lm', 'mlm_probability': 0.25, 'use_80_20_rule': True, 'disable_mlm': False, 'token_drop': 0.0}	False	24
amp_b8192_cb_o4_final	24	pile-readymade	torch-default	ScriptableCrammedBERT	1.970678448677063	115000	1	0.7271652965255406	2.0483789443969727			23:23:59.282404	8192	0.001	0	900000	37	2e382596fef989f92292d3d53214f2e7	/home/rostyslav/cramming/outputs	/home/rostyslav/cramming/outputs/data	amp_b8192_cb_o4_final/pretrain/2025-08-24/17-10-34	pile-readymade	{'hub': {'provider': 'hub'}}	JonasGeiping/the_pile_WordPiecex32768_2efdb9d060d1ae95faf952ec1a50f020	True	32768	128	['ScriptableCrammedBERT']	16	768	3072	0.1	LayerNorm	1e-12	pre	GELUglu	True	False	0.25	cross-entropy	MLM	{'vocab_size': None, 'pos_embedding': 'scaled-sinusoidal', 'dropout_prob': 0.1, 'pad_token_id': 0, 'max_seq_length': 128, 'embedding_dim': '${arch.hidden_size}', 'normalization': True, 'stable_low_precision': False}	{'type': 'self-attention', 'causal_attention': False, 'num_attention_heads': 12, 'dropout_prob': 0.1, 'skip_output_projection': False, 'qkv_bias': False, 'rotary_embedding': False, 'seq_op_in_fp32': False, 'sequence_op': 'torch-softmax'}	{'type': 'normal', 'std': 0.02}	1	True	False	True		{'pooler': 'avg', 'include_ff_layer': True, 'head_dim': 1024, 'nonlin': 'Tanh', 'classifier_dropout': '${arch.hidden_dropout_prob}'}	{'type': 'AdamW', 'lr': 0.001, 'betas': [0.9, 0.98], 'eps': 1e-12, 'weight_decay': 0.01, 'amsgrad': False, 'fused': None}	{'name': 'none'}	bert-o4	['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'norm']	0	0	900000	budget-triangle2	8192	0.6	0.5	False	{'name': 'masked-lm', 'mlm_probability': 0.25, 'use_80_20_rule': True, 'disable_mlm': False, 'token_drop': 0.0}	False	24
adamw+_36	24	pile-readymade	torch-default	ScriptableCrammedBERT	2.051222562789917	99000	1	0.7071996453771688				19:35:29.977745	8192	0.001	0	900000	36	2e382596fef989f92292d3d53214f2e7	/home/rostyslav/cramming/outputs	/home/rostyslav/cramming/outputs/data	adamw+_36/pretrain/2025-08-24/22-34-24	pile-readymade	{'hub': {'provider': 'hub'}}	JonasGeiping/the_pile_WordPiecex32768_2efdb9d060d1ae95faf952ec1a50f020	True	32768	128	['ScriptableCrammedBERT']	16	768	3072	0.1	LayerNorm	1e-12	pre	GELUglu	True	False	0.25	cross-entropy	MLM	{'vocab_size': None, 'pos_embedding': 'scaled-sinusoidal', 'dropout_prob': 0.1, 'pad_token_id': 0, 'max_seq_length': 128, 'embedding_dim': '${arch.hidden_size}', 'normalization': True, 'stable_low_precision': False}	{'type': 'self-attention', 'causal_attention': False, 'num_attention_heads': 12, 'dropout_prob': 0.1, 'skip_output_projection': False, 'qkv_bias': False, 'rotary_embedding': False, 'seq_op_in_fp32': False, 'sequence_op': 'torch-softmax'}	{'type': 'normal', 'std': 0.02}	1	True	False	True		{'pooler': 'avg', 'include_ff_layer': True, 'head_dim': 1024, 'nonlin': 'Tanh', 'classifier_dropout': '${arch.hidden_dropout_prob}'}	{'type': 'AdamW+', 'lr': 0.001, 'beta1': 0.9, 'beta2': 0.98, 'eps': 1e-12, 'weight_decay': 0.01, 'amsgrad': False, 'is_mask': False, 'is_lamb': False, 'weight_decouple': True, 'db_noise': -140}	{'name': 'none'}	bert-o4	['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'norm']	0	0	900000	budget-triangle2	8192	0.6	0.5	False	{'name': 'masked-lm', 'mlm_probability': 0.25, 'use_80_20_rule': True, 'disable_mlm': False, 'token_drop': 0.0}	False	24
adamw+_37	24	pile-readymade	torch-default	ScriptableCrammedBERT	1.9358569383621216	117000	1	0.7343927941729879	2.048567533493042			1 day 0:00:03.393145	8192	0.001	0	900000	37	2e382596fef989f92292d3d53214f2e7	/home/rostyslav/cramming/outputs	/home/rostyslav/cramming/outputs/data	adamw+_37/pretrain/2025-08-25/17-43-04	pile-readymade	{'hub': {'provider': 'hub'}}	JonasGeiping/the_pile_WordPiecex32768_2efdb9d060d1ae95faf952ec1a50f020	True	32768	128	['ScriptableCrammedBERT']	16	768	3072	0.1	LayerNorm	1e-12	pre	GELUglu	True	False	0.25	cross-entropy	MLM	{'vocab_size': None, 'pos_embedding': 'scaled-sinusoidal', 'dropout_prob': 0.1, 'pad_token_id': 0, 'max_seq_length': 128, 'embedding_dim': '${arch.hidden_size}', 'normalization': True, 'stable_low_precision': False}	{'type': 'self-attention', 'causal_attention': False, 'num_attention_heads': 12, 'dropout_prob': 0.1, 'skip_output_projection': False, 'qkv_bias': False, 'rotary_embedding': False, 'seq_op_in_fp32': False, 'sequence_op': 'torch-softmax'}	{'type': 'normal', 'std': 0.02}	1	True	False	True		{'pooler': 'avg', 'include_ff_layer': True, 'head_dim': 1024, 'nonlin': 'Tanh', 'classifier_dropout': '${arch.hidden_dropout_prob}'}	{'type': 'AdamW+', 'lr': 0.001, 'beta1': 0.9, 'beta2': 0.98, 'eps': 1e-12, 'weight_decay': 0.01, 'amsgrad': False, 'is_mask': False, 'is_lamb': False, 'weight_decouple': True, 'db_noise': -140}	{'name': 'none'}	bert-o4	['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'norm']	0	0	900000	budget-triangle2	8192	0.6	0.5	False	{'name': 'masked-lm', 'mlm_probability': 0.25, 'use_80_20_rule': True, 'disable_mlm': False, 'token_drop': 0.0}	False	24
adamw+_36	24	pile-readymade	torch-default	ScriptableCrammedBERT	1.9447015523910522	121000	1	0.7086795988141998	2.0561890602111816			1 day 0:00:04.915046	8192	0.001	0	900000	36	2e382596fef989f92292d3d53214f2e7	/home/rostyslav/cramming/outputs	/home/rostyslav/cramming/outputs/data	adamw+_36/pretrain/2025-08-25/20-19-21	pile-readymade	{'hub': {'provider': 'hub'}}	JonasGeiping/the_pile_WordPiecex32768_2efdb9d060d1ae95faf952ec1a50f020	True	32768	128	['ScriptableCrammedBERT']	16	768	3072	0.1	LayerNorm	1e-12	pre	GELUglu	True	False	0.25	cross-entropy	MLM	{'vocab_size': None, 'pos_embedding': 'scaled-sinusoidal', 'dropout_prob': 0.1, 'pad_token_id': 0, 'max_seq_length': 128, 'embedding_dim': '${arch.hidden_size}', 'normalization': True, 'stable_low_precision': False}	{'type': 'self-attention', 'causal_attention': False, 'num_attention_heads': 12, 'dropout_prob': 0.1, 'skip_output_projection': False, 'qkv_bias': False, 'rotary_embedding': False, 'seq_op_in_fp32': False, 'sequence_op': 'torch-softmax'}	{'type': 'normal', 'std': 0.02}	1	True	False	True		{'pooler': 'avg', 'include_ff_layer': True, 'head_dim': 1024, 'nonlin': 'Tanh', 'classifier_dropout': '${arch.hidden_dropout_prob}'}	{'type': 'AdamW+', 'lr': 0.001, 'beta1': 0.9, 'beta2': 0.98, 'eps': 1e-12, 'weight_decay': 0.01, 'amsgrad': False, 'is_mask': False, 'is_lamb': False, 'weight_decouple': True, 'db_noise': -140}	{'name': 'none'}	bert-o4	['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'norm']	0	0	900000	budget-triangle2	8192	0.6	0.5	False	{'name': 'masked-lm', 'mlm_probability': 0.25, 'use_80_20_rule': True, 'disable_mlm': False, 'token_drop': 0.0}	False	24
adamw_37	24	pile-readymade	torch-default	ScriptableCrammedBERT	2.0568082332611084	119000	1	0.7245292413735591	2.059415817260742			1 day 0:00:05.121776	8192	0.001	0	900000	37	2e382596fef989f92292d3d53214f2e7	/home/rostyslav/cramming/outputs	/home/rostyslav/cramming/outputs/data	adamw_37/pretrain/2025-08-26/17-49-56	pile-readymade	{'hub': {'provider': 'hub'}}	JonasGeiping/the_pile_WordPiecex32768_2efdb9d060d1ae95faf952ec1a50f020	True	32768	128	['ScriptableCrammedBERT']	16	768	3072	0.1	LayerNorm	1e-12	pre	GELUglu	True	False	0.25	cross-entropy	MLM	{'vocab_size': None, 'pos_embedding': 'scaled-sinusoidal', 'dropout_prob': 0.1, 'pad_token_id': 0, 'max_seq_length': 128, 'embedding_dim': '${arch.hidden_size}', 'normalization': True, 'stable_low_precision': False}	{'type': 'self-attention', 'causal_attention': False, 'num_attention_heads': 12, 'dropout_prob': 0.1, 'skip_output_projection': False, 'qkv_bias': False, 'rotary_embedding': False, 'seq_op_in_fp32': False, 'sequence_op': 'torch-softmax'}	{'type': 'normal', 'std': 0.02}	1	True	False	True		{'pooler': 'avg', 'include_ff_layer': True, 'head_dim': 1024, 'nonlin': 'Tanh', 'classifier_dropout': '${arch.hidden_dropout_prob}'}	{'type': 'AdamW', 'lr': 0.001, 'betas': [0.9, 0.98], 'eps': 1e-12, 'weight_decay': 0.01, 'amsgrad': False, 'fused': None}	{'name': 'none'}	bert-o4	['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'norm']	0	0	900000	budget-triangle2	8192	0.6	0.5	False	{'name': 'masked-lm', 'mlm_probability': 0.25, 'use_80_20_rule': True, 'disable_mlm': False, 'token_drop': 0.0}	False	24
adamw_38	24	pile-readymade	torch-default	ScriptableCrammedBERT	1.967969536781311	124000	1	0.6966727528975855	2.072986602783203			1 day 0:00:04.636598	8192	0.001	0	900000	38	2e382596fef989f92292d3d53214f2e7	/home/rostyslav/cramming/outputs	/home/rostyslav/cramming/outputs/data	adamw_38/pretrain/2025-08-26/22-17-59	pile-readymade	{'hub': {'provider': 'hub'}}	JonasGeiping/the_pile_WordPiecex32768_2efdb9d060d1ae95faf952ec1a50f020	True	32768	128	['ScriptableCrammedBERT']	16	768	3072	0.1	LayerNorm	1e-12	pre	GELUglu	True	False	0.25	cross-entropy	MLM	{'vocab_size': None, 'pos_embedding': 'scaled-sinusoidal', 'dropout_prob': 0.1, 'pad_token_id': 0, 'max_seq_length': 128, 'embedding_dim': '${arch.hidden_size}', 'normalization': True, 'stable_low_precision': False}	{'type': 'self-attention', 'causal_attention': False, 'num_attention_heads': 12, 'dropout_prob': 0.1, 'skip_output_projection': False, 'qkv_bias': False, 'rotary_embedding': False, 'seq_op_in_fp32': False, 'sequence_op': 'torch-softmax'}	{'type': 'normal', 'std': 0.02}	1	True	False	True		{'pooler': 'avg', 'include_ff_layer': True, 'head_dim': 1024, 'nonlin': 'Tanh', 'classifier_dropout': '${arch.hidden_dropout_prob}'}	{'type': 'AdamW', 'lr': 0.001, 'betas': [0.9, 0.98], 'eps': 1e-12, 'weight_decay': 0.01, 'amsgrad': False, 'fused': None}	{'name': 'none'}	bert-o4	['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'norm']	0	0	900000	budget-triangle2	8192	0.6	0.5	False	{'name': 'masked-lm', 'mlm_probability': 0.25, 'use_80_20_rule': True, 'disable_mlm': False, 'token_drop': 0.0}	False	24
